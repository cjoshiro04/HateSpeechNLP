{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fdc031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "#Logistic Regression Imports\n",
    "from sklearn import linear_model\n",
    "\n",
    "#KNN Imports\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "#model functions\n",
    "def train_svm(df, df_xcols, df_ycol, kernel_type):\n",
    "    x_svm = df_xcols\n",
    "    y_svm = df[df_ycol]\n",
    "    # Split dataset into training set and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_svm, y_svm, test_size=0.3) # 70% training and 30% test\n",
    "\n",
    "    clf = SVC(kernel=kernel_type)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Model Accuracy: how often is the classifier correct?\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    #Model Precision\n",
    "    print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "\n",
    "    #Model Recall\n",
    "    print(\"Recall:\",metrics.recall_score(y_test, y_pred))\n",
    "    \n",
    "    #Model F1 Score\n",
    "    print(\"F1 Score: \", metrics.f1_score(y_test, y_pred))\n",
    "    \n",
    "    return clf\n",
    "    \n",
    "def train_logr(df, feature_cols, df_ycol):\n",
    "    x_logr = feature_cols\n",
    "    y_logr = df[df_ycol]\n",
    "    # Split dataset into training set and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_logr, y_logr, test_size=0.3) # 70% training and 30% test\n",
    "\n",
    "    logr = linear_model.LogisticRegression(max_iter = 1000)#increased max iter bc when...\n",
    "    #passing in all features, algorithm doesn't converge so have to adjust max_iter\n",
    "    logr.fit(X_train, y_train.values.ravel())\n",
    "    y_pred = logr.predict(X_test)\n",
    "    \n",
    "    # Model Accuracy: how often is the classifier correct?\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    #Model Precision\n",
    "    print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "\n",
    "    #Model Recall\n",
    "    print(\"Recall:\",metrics.recall_score(y_test, y_pred))\n",
    "    \n",
    "    #Model F1 Score\n",
    "    print(\"F1 Score: \", metrics.f1_score(y_test, y_pred))\n",
    "    \n",
    "    return logr\n",
    "\n",
    "def train_KNN(df, feature_cols, df_ycol, neighbors):\n",
    "\n",
    "    # Create feature and target arrays \n",
    "    x_KNN = feature_cols\n",
    "    y_KNN = df[df_ycol]\n",
    "\n",
    "    # Split into training and test set \n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_KNN, y_KNN, test_size = 0.3) \n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=neighbors) \n",
    "\n",
    "    knn.fit(X_train, y_train) \n",
    "\n",
    "    # Predict on dataset which model has not seen before \n",
    "    y_pred = knn.predict(X_test)\n",
    "    \n",
    "    # Model Accuracy: how often is the classifier correct?\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    #Model Precision\n",
    "    print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "\n",
    "    #Model Recall\n",
    "    print(\"Recall:\",metrics.recall_score(y_test, y_pred))\n",
    "    \n",
    "    #Model F1 Score\n",
    "    print(\"F1 Score: \", metrics.f1_score(y_test, y_pred))\n",
    "    \n",
    "    return knn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e769f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import csv's\n",
    "instadf = pd.read_csv(\"insta_data.csv\")\n",
    "ytdf = pd.read_csv(\"youtube_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8674dc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training SVM on specific TM (Topic Modeling) Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3b0856e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5491905354919053\n",
      "Precision: 0.5714285714285714\n",
      "Recall: 0.03287671232876712\n",
      "F1 Score:  0.06217616580310881\n"
     ]
    }
   ],
   "source": [
    "LdaOnly = instadf.drop(columns=[\"Clickbait\", \"Bert Feature\", \"LSA Feature\"])\n",
    "instamodel = train_svm(instadf, LdaOnly, \"Clickbait\", \"rbf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3270f3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5516811955168119\n",
      "Precision: 0.4883720930232558\n",
      "Recall: 0.02920723226703755\n",
      "F1 Score:  0.05511811023622047\n"
     ]
    }
   ],
   "source": [
    "BertOnly = instadf.drop(columns=[\"Clickbait\", \"LDA Feature\", \"LSA Feature\"])\n",
    "instamodel = train_svm(instadf, BertOnly, \"Clickbait\", \"rbf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "25a38c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5610211706102117\n",
      "Precision: 0.6\n",
      "Recall: 0.037815126050420166\n",
      "F1 Score:  0.07114624505928854\n"
     ]
    }
   ],
   "source": [
    "LSAOnly = instadf.drop(columns=[\"Clickbait\", \"LDA Feature\", \"Bert Feature\"])\n",
    "instamodel = train_svm(instadf, LSAOnly, \"Clickbait\", \"rbf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dcd5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Logistic Regression Models on specific TM Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "502d41f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7291407222914073\n",
      "Precision: 0.6961038961038961\n",
      "Recall: 0.7272727272727273\n",
      "F1 Score:  0.7113470471134705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "instamodel = train_logr(instadf, instadf.drop(columns=[\"Clickbait\"]), \"Clickbait\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "37730743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7733499377334994\n",
      "Precision: 0.7064102564102565\n",
      "Recall: 0.8032069970845481\n",
      "F1 Score:  0.7517053206002728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "LDAOnly = instadf.drop(columns=[\"Clickbait\", \"LDA Feature\", \"LSA Feature\"])\n",
    "instamodel = train_logr(instadf, LDAOnly, \"Clickbait\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e61999ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7627646326276464\n",
      "Precision: 0.7208387942332897\n",
      "Recall: 0.766016713091922\n",
      "F1 Score:  0.7427413909520594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "BertOnly = instadf.drop(columns=[\"Clickbait\", \"LDA Feature\", \"LSA Feature\"])\n",
    "instamodel = train_logr(instadf, BertOnly, \"Clickbait\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b6d245a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7652552926525529\n",
      "Precision: 0.7259923175416133\n",
      "Recall: 0.7767123287671233\n",
      "F1 Score:  0.7504963600264726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "LSAOnly = instadf.drop(columns=[\"Clickbait\", \"LDA Feature\", \"Bert Feature\"])\n",
    "instamodel = train_logr(instadf, LSAOnly, \"Clickbait\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0a02cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Traning KNN on specific TM Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3342b04c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5560398505603985\n",
      "Precision: 0.487062404870624\n",
      "Recall: 0.45977011494252873\n",
      "F1 Score:  0.4730229120473023\n"
     ]
    }
   ],
   "source": [
    "instamodel = train_KNN(instadf, instadf.drop(columns=[\"Clickbait\"]), \"Clickbait\", 7)#Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "30a7fde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5672478206724783\n",
      "Precision: 0.5191176470588236\n",
      "Recall: 0.4895977808599168\n",
      "F1 Score:  0.5039257673090649\n"
     ]
    }
   ],
   "source": [
    "LDAOnly = instadf.drop(columns=[\"Clickbait\", \"LDA Feature\", \"LSA Feature\"])\n",
    "instamodel = train_KNN(instadf, LDAOnly, \"Clickbait\", 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9b997cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.549813200498132\n",
      "Precision: 0.486646884272997\n",
      "Recall: 0.4652482269503546\n",
      "F1 Score:  0.4757070340826686\n"
     ]
    }
   ],
   "source": [
    "BertOnly = instadf.drop(columns=[\"Clickbait\", \"LDA Feature\", \"LSA Feature\"])\n",
    "instamodel = train_KNN(instadf, BertOnly, \"Clickbait\", 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ceca8867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5579078455790785\n",
      "Precision: 0.49765258215962443\n",
      "Recall: 0.4497878359264498\n",
      "F1 Score:  0.4725111441307578\n"
     ]
    }
   ],
   "source": [
    "LSAOnly = instadf.drop(columns=[\"Clickbait\", \"LDA Feature\", \"Bert Feature\"])\n",
    "instamodel = train_KNN(instadf, LSAOnly, \"Clickbait\", 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e144e413",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (1.2.4)\n",
      "Requirement already satisfied: tensorflow in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (2.13.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (from pandas) (1.21.6)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (16.0.6)\n",
      "Collecting numpy>=1.16.5 (from pandas)\n",
      "  Downloading numpy-1.24.3-cp39-cp39-macosx_10_9_x86_64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (4.23.1)\n",
      "Requirement already satisfied: setuptools in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (67.7.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.56.2)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.13.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.32.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn) (1.8.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.18.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (from packaging->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: urllib3<2.0 in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/codyoshiro/opt/anaconda3/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n",
      "Downloading numpy-1.24.3-cp39-cp39-macosx_10_9_x86_64.whl (19.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.6\n",
      "    Uninstalling numpy-1.21.6:\n",
      "      Successfully uninstalled numpy-1.21.6\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.5.0 requires daal==2021.4.0, which is not installed.\n",
      "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.24.3\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas tensorflow scikit-learn #Installing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53fcb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Traning SVM on specific TM Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4774cf7c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8085106382978723\n",
      "Precision: 0.9230769230769231\n",
      "Recall: 0.6\n",
      "F1 Score:  0.7272727272727273\n"
     ]
    }
   ],
   "source": [
    "ytmodel = train_svm(ytdf, ytdf.drop(columns=[\"class\", \"LDA Feature\", \"LSA Feature\"]), 'class', 'rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cffbc7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7446808510638298\n",
      "Precision: 0.8571428571428571\n",
      "Recall: 0.5454545454545454\n",
      "F1 Score:  0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "ytmodel = train_svm(ytdf, ytdf.drop(columns=[\"class\", \"Bert Feature\", \"LSA Feature\"]), 'class', 'rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8880149d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.723404255319149\n",
      "Precision: 0.8571428571428571\n",
      "Recall: 0.5217391304347826\n",
      "F1 Score:  0.6486486486486487\n"
     ]
    }
   ],
   "source": [
    "ytmodel = train_svm(ytdf, ytdf.drop(columns=[\"class\", \"LDA Feature\", \"Bert Feature\"]), 'class', 'rbf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5003f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Logistic Regression Models on specific TM Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f28223ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9787234042553191\n",
      "Precision: 0.9583333333333334\n",
      "Recall: 1.0\n",
      "F1 Score:  0.9787234042553191\n"
     ]
    }
   ],
   "source": [
    "ytmodel = train_logr(ytdf, ytdf.drop(columns=[\"class\", \"LDA Feature\", \"LSA Feature\"]), \"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21c1a977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9574468085106383\n",
      "Precision: 1.0\n",
      "Recall: 0.9090909090909091\n",
      "F1 Score:  0.9523809523809523\n"
     ]
    }
   ],
   "source": [
    "ytmodel = train_logr(ytdf, ytdf.drop(columns=[\"class\", \"LDA Feature\", \"LSA Feature\"]), \"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25e27fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9361702127659575\n",
      "Precision: 1.0\n",
      "Recall: 0.8695652173913043\n",
      "F1 Score:  0.9302325581395349\n"
     ]
    }
   ],
   "source": [
    "ytmodel = train_logr(ytdf, ytdf.drop(columns=[\"class\", \"Bert Feature\", \"LSA Feature\"]), \"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f0ddb71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9787234042553191\n",
      "Precision: 0.9615384615384616\n",
      "Recall: 1.0\n",
      "F1 Score:  0.9803921568627451\n"
     ]
    }
   ],
   "source": [
    "ytmodel = train_logr(ytdf, ytdf.drop(columns=[\"class\", \"Bert Feature\", \"LDA Feature\"]), \"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2648ecf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Traning KNN Model on specific TM Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b5a6b0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7872340425531915\n",
      "Precision: 0.6842105263157895\n",
      "Recall: 0.7647058823529411\n",
      "F1 Score:  0.7222222222222222\n"
     ]
    }
   ],
   "source": [
    "ytmodel = train_KNN(ytdf, ytdf.drop(columns=[\"class\", \"LDA Feature\", \"LSA Feature\"]), \"class\", 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "44904c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.851063829787234\n",
      "Precision: 0.8947368421052632\n",
      "Recall: 0.7727272727272727\n",
      "F1 Score:  0.8292682926829268\n"
     ]
    }
   ],
   "source": [
    "ytmodel = train_KNN(ytdf, ytdf.drop(columns=[\"class\", \"Bert Feature\", \"LSA Feature\"]), \"class\", 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7ab51704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.851063829787234\n",
      "Precision: 0.8260869565217391\n",
      "Recall: 0.8636363636363636\n",
      "F1 Score:  0.8444444444444444\n"
     ]
    }
   ],
   "source": [
    "ytmodel = train_KNN(ytdf, ytdf.drop(columns=[\"class\", \"Bert Feature\", \"LDA Feature\"]), \"class\", 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276232e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
